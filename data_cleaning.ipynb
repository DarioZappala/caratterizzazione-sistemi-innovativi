{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'ExCo': ['ceo', 'cto', 'cfo', 'coo', 'cmo', 'cio', 'cso', 'cpo', 'cco', 'cro', 'svp', 'evp', 'cdo', 'cbo', 'cxo'],\n",
    "    'Founder': ['founder'],\n",
    "    'Engineering': ['software engineer', 'data scientist'],\n",
    "    'Leadership': ['president', 'managing director', 'director', 'vp', 'chairman', 'executive director', 'general manager', 'vp engineering'],\n",
    "    'Board': ['board member', 'member board director', 'board directors', 'chairman board', 'advisory board member', 'board observer'],\n",
    "    'Ownership': ['owner', 'partner', 'managing partner', 'founding partner'],\n",
    "    'Investor':['investor'],\n",
    "    'Advisory': ['advisor', 'consultant'],\n",
    "    'Other': ['member', 'team member', 'associate', 'product manager', 'principal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org         = pd.read_csv('../data/organizations.csv')\n",
    "df_jobs        = pd.read_csv('../data/jobs.csv')\n",
    "df_people      = pd.read_csv('../data/people.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the job dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe 'df_jobs' to avoid modifying the original dataframe\n",
    "pple_new_roles = df_jobs.copy()\n",
    "\n",
    "# Apply the 'clean_text' function to the 'title' column to clean the text in each title,\n",
    "# and store the results in a new column called 'cleaned_title'\n",
    "pple_new_roles['cleaned_title'] = pple_new_roles['title'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Group the dataframe by the 'cleaned_title' column and count the occurrences of each unique title.\n",
    "# Then, sort these counts in descending order.\n",
    "sorted_counts = pple_new_roles.groupby('cleaned_title')['cleaned_title'].count().sort_values(ascending=False)\n",
    "\n",
    "# Reset the index of the resulting Series to turn it into a DataFrame,\n",
    "# and name the count column 'count'\n",
    "sorted_counts_df = sorted_counts.reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of chief executive jobs in the data, we want to use the same abreviation for each job description. We start by creating a chief_job_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find job titles containing the word 'chief' and reset the index\n",
    "cumulative_chief = (\n",
    "    find_job_word(sorted_counts_df, 'cleaned_title', 'chief')\n",
    "    .reset_index()  # Reset the index to make it a column\n",
    "    .assign(cumulative_count=lambda x: x['count'].cumsum())  # Add a new column with cumulative sum\n",
    ")\n",
    "\n",
    "# Normalize the cumulative count by the total cumulative count\n",
    "norm = cumulative_chief['cumulative_count'].tail(1).values[0]\n",
    "cumulative_chief['percentage_cumulative'] = cumulative_chief['cumulative_count'] / norm\n",
    "\n",
    "# Apply various abbreviation functions to the cleaned titles\n",
    "# We need to run abbreviation strategy three times as it is an incremental process.\n",
    "# Check the abbreviated_cleaned_title, abbreviated_cleaned_title_round2, and abbreviated_cleaned_title_round3\n",
    "# to observe the differences\n",
    "cumulative_chief['abbreviated_cleaned_title'] = cumulative_chief['cleaned_title'].apply(abbreviate_title)\n",
    "cumulative_chief['abbreviated_cleaned_title_round2'] = cumulative_chief['abbreviated_cleaned_title'].apply(abbreviate_title_round_2)\n",
    "cumulative_chief['abbreviated_cleaned_title_round3'] = cumulative_chief['abbreviated_cleaned_title_round2'].apply(lambda x: remove_executives(x))\n",
    "\n",
    "# Uncomment the following line to filter rows where percentage cumulative is less than 0.60\n",
    "# cumulative_chief[cumulative_chief['percentage_cumulative'] < 0.60]\n",
    "\n",
    "# Create a DataFrame for chief job titles with their counts, sorted in descending order\n",
    "chief_job_dataframe = (\n",
    "    find_job_word(sorted_counts_df, 'cleaned_title', 'chief')\n",
    "    .groupby('cleaned_title')\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=False)\n",
    "    .rename(columns={'index': 'chief_jobs'})\n",
    ")\n",
    "\n",
    "# Apply abbreviation functions to the cleaned titles in the chief_df DataFrame\n",
    "chief_df = find_job_word(sorted_counts_df, 'cleaned_title', 'chief')\n",
    "chief_df['abbreviated_cleaned_title'] = chief_df['cleaned_title'].apply(abbreviate_title)\n",
    "chief_df['abbreviated_cleaned_title_round2'] = chief_df['abbreviated_cleaned_title'].apply(abbreviate_title_round_2)\n",
    "chief_df['abbreviated_cleaned_title_round3'] = chief_df['abbreviated_cleaned_title_round2'].apply(lambda x: remove_executives(x))\n",
    "\n",
    "# Repeat the process to ensure cumulative_chief is updated with abbreviations and cumulative counts\n",
    "cumulative_chief = (\n",
    "    find_job_word(sorted_counts_df, 'cleaned_title', 'chief')\n",
    "    .reset_index()  # Reset the index to make it a column\n",
    "    .assign(cumulative_count=lambda x: x['count'].cumsum())  # Add a new column with cumulative sum\n",
    ")\n",
    "norm = cumulative_chief['cumulative_count'].tail(1).values[0]\n",
    "cumulative_chief['percentage_cumulative'] = cumulative_chief['cumulative_count'] / norm\n",
    "cumulative_chief['abbreviated_cleaned_title'] = cumulative_chief['cleaned_title'].apply(abbreviate_title)\n",
    "cumulative_chief['abbreviated_cleaned_title_round2'] = cumulative_chief['abbreviated_cleaned_title'].apply(abbreviate_title_round_2)\n",
    "cumulative_chief['abbreviated_cleaned_title_round3'] = cumulative_chief['abbreviated_cleaned_title_round2'].apply(lambda x: remove_executives(x))\n",
    "\n",
    "# Uncomment the following line to filter rows where percentage cumulative is less than 0.60\n",
    "# cumulative_chief[cumulative_chief['percentage_cumulative'] < 0.60]\n",
    "\n",
    "# Apply abbreviation functions to the cleaned titles in the chief_df DataFrame\n",
    "chief_df = find_job_word(sorted_counts_df, 'cleaned_title', 'chief')\n",
    "chief_df['abbreviated_cleaned_title'] = chief_df['cleaned_title'].apply(abbreviate_title)\n",
    "chief_df['abbreviated_cleaned_title_round2'] = chief_df['abbreviated_cleaned_title'].apply(abbreviate_title_round_2)\n",
    "chief_df['abbreviated_cleaned_title_round3'] = chief_df['abbreviated_cleaned_title_round2'].apply(lambda x: remove_executives(x))\n",
    "\n",
    "# Create a dictionary mapping cleaned_title to abbreviated_cleaned_title_round3\n",
    "title_mapping = chief_df.set_index('cleaned_title')['abbreviated_cleaned_title_round3'].to_dict()\n",
    "\n",
    "# Merge the new roles DataFrame with chief_df to get the abbreviated titles\n",
    "new_df = pd.merge(pple_new_roles, chief_df[['cleaned_title', 'abbreviated_cleaned_title_round3']], \n",
    "                  how='left', \n",
    "                  on='cleaned_title')\n",
    "\n",
    "# Create the final_title column based on the title mapping\n",
    "new_df['final_title'] = new_df['cleaned_title'].where(\n",
    "    ~new_df['cleaned_title'].isin(title_mapping),\n",
    "    new_df['abbreviated_cleaned_title_round3']\n",
    ")\n",
    "\n",
    "# Drop rows where 'started_on' is NaN\n",
    "new_df = new_df.dropna(subset=['started_on'])\n",
    "\n",
    "# Move the word 'Founder' to the end of the title\n",
    "new_df['final_final_title'] = new_df['final_title'].apply(move_founder_to_end)\n",
    "\n",
    "# Group by the final_final_title and count occurrences, then sort and rename columns\n",
    "tmp_df = new_df \\\n",
    "    .groupby('final_final_title') \\\n",
    "    .size() \\\n",
    "    .reset_index(name='count') \\\n",
    "    .sort_values(by='count', ascending=False) \\\n",
    "    .rename(columns={'index': 'three_letter_title'}) \\\n",
    "    .head(60)\n",
    "\n",
    "# Calculate cumulative counts for tmp_df\n",
    "cumulative_tmp_df = (\n",
    "    tmp_df\n",
    "    .reset_index()  # Reset the index to make it a column\n",
    "    .assign(cumulative_count=lambda x: x['count'].cumsum())  # Add a new column with cumulative sum\n",
    ")\n",
    "norm = cumulative_tmp_df['cumulative_count'].tail(1).values[0]\n",
    "cumulative_tmp_df['percentage_cumulative'] = cumulative_tmp_df['cumulative_count'] / norm\n",
    "\n",
    "# Uncomment the following line to display the top 10 rows of cumulative_tmp_df\n",
    "# cumulative_tmp_df.head(10)\n",
    "\n",
    "# Create a DataFrame for three-letter titles and their counts, sorted in descending order\n",
    "three_letter_titles = (\n",
    "    new_df[new_df['cleaned_title'].str.len() == 3]\n",
    "    .groupby('cleaned_title')\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=False)\n",
    "    .rename(columns={'index': 'three_letter_title'})\n",
    ")\n",
    "\n",
    "# # Calculate cumulative counts for three_letter_titles\n",
    "# cumulative_three_letter = (\n",
    "#     three_letter_titles\n",
    "#     .reset_index()  # Reset the index to make it a column\n",
    "#     .assign(cumulative_count=lambda x: x['count'].cumsum())  # Add a new column with cumulative sum\n",
    "# )\n",
    "\n",
    "# norm = cumulative_three_letter['cumulative_count'].tail(1).values[0]\n",
    "# cumulative_three_letter['percentage_cumulative'] = cumulative_three_letter['cumulative_count'] / norm\n",
    "\n",
    "# Uncomment the following line to display the top 10 rows of cumulative_three_letter\n",
    "# cumulative_three_letter.head(10)\n",
    "\n",
    "# Call the group_roles function to group roles in new_df based on the 'final_final_title' column\n",
    "grouped_df = group_roles(new_df, 'final_final_title', groups)\n",
    "grouped_df['group'] = grouped_df['group'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Select relevant columns and convert 'started_on' to datetime\n",
    "df_jobs_cleaned = grouped_df[['started_on', 'org_uuid', 'group', 'person_uuid']]\n",
    "df_jobs_cleaned['started_on'] = pd.to_datetime(df_jobs_cleaned['started_on'], errors='coerce')\n",
    "df_jobs_cleaned = df_jobs_cleaned[df_jobs_cleaned['started_on'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_cleaned.to_csv('data_output/jobs_cleaned.csv',index=False)\n",
    "\n",
    "# To read correctly the dataframe use the following\n",
    "# df = pd.read_csv('data_output/jobs_cleaned.csv',\n",
    "#                  converters={'group': str_to_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select relevant columns from df_org and convert 'founded_on' to datetime\n",
    "# df_org_foundation = df_org[['uuid', 'founded_on', 'country_code', 'city', 'total_funding_usd']]\n",
    "# df_org_foundation['founded_on'] = pd.to_datetime(df_org_foundation['founded_on'], errors='coerce')\n",
    "# df_org_foundation = df_org_foundation[df_org_foundation['founded_on'].notna()]\n",
    "# df_org_foundation = df_org_foundation[df_org_foundation['country_code'].notna()]\n",
    "\n",
    "# # Create a list of dimension labels from the keys of the groups dictionary\n",
    "# dimension_labels = list(groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
